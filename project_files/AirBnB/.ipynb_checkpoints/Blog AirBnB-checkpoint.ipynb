{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AirBnB Project for  **Project: Write A Data Science Blog Post**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1  Key Steps for Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to be creative with your solutions, but do follow the CRISP-DM process in finding your solutions.\n",
    "\n",
    "1) Pick a dataset.\n",
    "   I chose the AirBnnB dataset.  Because why not..\n",
    "\n",
    "2) Pose at least three questions related to business or real-world applications of how the data could be used.\n",
    "\n",
    "3) Create a Jupyter Notebook, using any associated packages you'd like, to:\n",
    "\n",
    "    Prepare data:\n",
    "        Gather necessary data to answer your questions\n",
    "        Handle categorical and missing data\n",
    "        Provide insight into the methods you chose and why you chose them\n",
    "\n",
    "    Analyze, Model, and Visualize\n",
    "        Provide a clear connection between your business questions and how the data answers them.\n",
    "\n",
    "4) Communicate your business insights:\n",
    "\n",
    "    Create a Github repository to share your code and data wrangling/modeling techniques, with a technical audience in mind\n",
    "    Create a blog post to share your questions and insights with a non-technical audience\n",
    "\n",
    "Your deliverables will be a Github repo and a blog post. Use the rubric here to assist in successfully completing this project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 [Rubric](https://review.udacity.com/#!/rubrics/1507/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Functionality and Readability\n",
    "* Code is readable (uses good coding practices - PEP8) \n",
    "* Code is functional.\n",
    "* Write code that is well documented and uses functions and classes as necessary.\n",
    "\n",
    "#### Data\n",
    "* Project follows the CRISP-DM Process while analyzing their data.\n",
    "* Proper handling of categorical and missing values in the dataset.\n",
    "* Categorical variables are handled appropriately for machine learning models (if models are created). \n",
    "\n",
    "#### Analysis, Modeling, Visualization\n",
    "* There are 3-5 business questions answered.\n",
    "\t\n",
    "#### Github Repository\n",
    "* Student must publish their code in a public Github repository.\n",
    "\t\n",
    "#### Blog Post\n",
    "* Communicate their findings with stakeholders.\n",
    "* There should be an intriguing title and image related to the project.\n",
    "* The body of the post has paragraphs that are broken up by appropriate white space and images.\n",
    "* Each question has a clearly communicated solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  0.3  CRISP-DM\n",
    "### 0.3.1 Business Understanding/Data Understanding\n",
    "          AirBnB is an online marketplace for vacation/temporary houseing rentals.  Thier members/hosts own the property and rent via the  AirBnB marketplace.\n",
    "          \n",
    "          The data provides was provided each from Seattle and Bostom\n",
    "          * listing.csv\n",
    "          * calendar.csv\n",
    "          * reviews.csv\n",
    "          \n",
    "          How to best position your property to make the most revenue?\n",
    "          1) What time of year is best to make your property availible to get the most money?\n",
    "              Summer months for most properties, but there seem to bes some very high outliers around the holidays...\n",
    "          2) Know your capacity?   What neighborhoods/property type/property attributes sell better?\n",
    "   \n",
    "          3) What do you need in your profile to garuntee your property is reviewed and reviewed high\n",
    "          \n",
    "          \n",
    "### 0.3.2 Data Preparation\n",
    "        1) Imported listing and calendar\n",
    "        #clean_cal() and clean_listing()\n",
    "        2) Corrected and adjusted datatypes  \n",
    "        3) Took some columns and made them into booleans (presnence or absence of awnser)\n",
    "        \n",
    "        \n",
    "     \n",
    "#### 0.3.2.1 Cleaning Data\n",
    "        Price is our response variable\n",
    "        1) removed all rows where price was NA\n",
    "        2) Removed a column that was mostly NAs\n",
    "        3) removed a few rows of the remaining NA\n",
    "        \n",
    "        \n",
    "### 0.3.3 Modeling\n",
    "### 0.3.4 Evaluation\n",
    "### 0.3.5 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "\n",
    "#stats\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import ast\n",
    "import math\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "#Graphing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import helper as h\n",
    "\n",
    "#Data modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.decomposition import pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()+\"\\All Data\"\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_listings(df):\n",
    "    ''' Return a cleaned dataframe derived from listing.csv file\n",
    "\n",
    "    1) Fixes percentage & currency strings to float\n",
    "    2) Fixes datatype of oject to categories were appropraite\n",
    "    3) Fixes bool strings to bool cols\n",
    "    2) Fixes Datetime cols -> datetime format\n",
    "    3) There are two columns that have list containing strings, convert to one hot encoded columns \n",
    "    4) \n",
    "    5) \n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    df:  Pandas DataFrame with an already imported lsiting.csv\n",
    "\n",
    "    '''\n",
    "\n",
    "    ## Clean percentage strings to float values\n",
    "    pct_col = ['host_acceptance_rate','host_response_rate']\n",
    "    for pc in pct_col:\n",
    "        df[pc] = df[pc].str.strip(\"%\")\n",
    "        df[pc] = df[pc].astype('float')\n",
    "        df[pc] = df[pc].apply(lambda x: x/100)\n",
    "        #df[pc] = df[pc].map('{:,.2%}'.format)\n",
    "        \n",
    "    ## Clean dollar strings to value\n",
    "\n",
    "    dol_col = ['price','weekly_price','monthly_price','security_deposit','cleaning_fee','extra_people']\n",
    "    for dol in dol_col:\n",
    "        df[dol] = df[dol].str.replace('$','')\n",
    "        df[dol] = df[dol].str.replace(',','')\n",
    "        df[dol] = df[dol].astype('float')\n",
    "        #df[dol] = df[dol].map('${:,.2f}'.format)\n",
    "        \n",
    "    ## Change type to category\n",
    "    cat_col = ['host_response_time','host_location','host_neighbourhood','neighbourhood',\n",
    "               'neighbourhood_cleansed','neighbourhood_group_cleansed','city','state','zipcode',\n",
    "              'market','smart_location','country_code','country','property_type','room_type',\n",
    "              'calendar_updated','jurisdiction_names','cancellation_policy','bed_type']\n",
    "    \n",
    "    for cc in cat_col:\n",
    "        df[cc] = df[cc].astype('category')\n",
    "  \n",
    "\n",
    "    ## Fix Boolean Columns\n",
    "    bool_col = ['host_is_superhost','host_has_profile_pic','host_identity_verified',\n",
    "                'is_location_exact','has_availability','requires_license','instant_bookable',\n",
    "               'require_guest_profile_picture','require_guest_phone_verification']\n",
    "    for bc in bool_col:\n",
    "        df[bc] = df[bc].replace({'t': True,'f':False})\n",
    "        df[bc] = df[bc].astype(bool)\n",
    "\n",
    "    ## Fix Datetime columns\n",
    "    dt_col = ['last_scraped','host_since','calendar_last_scraped','first_review','last_review']\n",
    "    for dt in dt_col:\n",
    "        df[dt] = pd.to_datetime(df[dt])\n",
    "\n",
    "    ## Fix list column\n",
    "    ## The following code transforms column 'host_verification' to a usable matrix of \n",
    "    ##     one hot encoding the contained communicaiton methods      \n",
    "    \n",
    "    df2 = pd.DataFrame(df['host_verifications'].apply(lambda x:ast.literal_eval(x)))  # string to list #\n",
    "    df3 = df2.host_verifications.apply(pd.Series)                                   # list -> series across columns #\n",
    "    df2 = df2.merge(df3, right_index=True, left_index=True)\n",
    "    df2 = df2.reset_index().melt(id_vars=['id','host_verifications'],value_name = 'host_sm_ver')\n",
    "    df2 = df2.pivot_table(values='variable',columns='host_sm_ver',index='id',aggfunc='count',fill_value=0)\n",
    "    df2 = df2.add_prefix('hv::')\n",
    "    df = df.merge(df2,left_index=True, right_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    df4 = pd.DataFrame(df_listing['amenities'].apply(lambda x:\n",
    "                           x.replace('\\\"','').replace('{','').replace('}','').split(',')))\n",
    "    df5 = df4.iloc[:,0].apply(pd.Series)\n",
    "    df4 = df4.merge(df5,left_index=True,right_index=True)\n",
    "    df4 = df4.reset_index().melt(id_vars=['id','amenities'],value_name = 'amms')\n",
    "    df4 = df4.pivot_table(values='variable',columns='amms',index='id',aggfunc='count',fill_value=0)\n",
    "    df4 = df4.add_prefix('amm::')\n",
    "    df = df.merge(df4,left_index=True, right_index=True)\n",
    "    \n",
    "    ## Remaining string columns, only interested in the presence or absence.   Replace with boolean. \n",
    "    \n",
    "    \n",
    "    str_cols = ['summary', 'space', 'neighborhood_overview', 'notes', 'transit',\n",
    "   'thumbnail_url', 'medium_url', 'xl_picture_url', 'host_about']\n",
    "    \n",
    "    def replace_str(x):\n",
    "        if type(x) == float:\n",
    "            if  math.isnan(x):\n",
    "                return False\n",
    "        else: return True\n",
    "    \n",
    "    df_listed_attributes = pd.DataFrame()\n",
    "    for col in str_cols:\n",
    "        df_listed_attributes[col] = df[col].apply(lambda x: replace_str(x))\n",
    "        df_listed_attributes[col] = df_listed_attributes[col].astype('bool')\n",
    "    \n",
    "    df_listed_attributes = df_listed_attributes.add_prefix('attrib::')\n",
    "    df = df.merge(df_listed_attributes,left_index=True,right_index=True)\n",
    "    df = df.drop(columns=str_cols)\n",
    "    \n",
    "    \n",
    "    ## Drop Columns\n",
    "    '''Reasons\n",
    "    All N/A: licence\n",
    "    No N/A: listing_url\n",
    "    onehot: host_verifications\n",
    "    am\n",
    "       \n",
    "    '''\n",
    "    drop_cols = ['license','host_verifications','amenities']  \n",
    "    df = df.drop(columns=drop_cols)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cal(df):\n",
    "    ''' Return a cleaned dataframe derived from listing.csv file\n",
    "\n",
    "    1) Fixes Datetime cols -> datetime format\n",
    "    2) Fixes percentage strings to float\n",
    "    3) Fixes bool strings to bool cols\n",
    "    4) Fixes datatype of oject to categories were appropraite\n",
    "    5) \n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    df:  Pandas DataFrame with an already imported lsiting.csv\n",
    "\n",
    "    '''\n",
    "    dol_col= ['price']\n",
    "    for dol in dol_col:\n",
    "        df[dol] = df[dol].str.replace('$','')\n",
    "        df[dol] = df[dol].str.replace(',','')\n",
    "        df[dol] = df[dol].astype('float')\n",
    "        \n",
    "    ## Fix Datetime columns\n",
    "    dt_col = ['date']\n",
    "    for dt in dt_col:\n",
    "        df[dt] = pd.to_datetime(df[dt])\n",
    "\n",
    "        \n",
    "    ## Expand Datetime\n",
    "    df['week_num'] = df['date'].apply(lambda x: date.isocalendar(x)[1])\n",
    "    df['month'] = df['date'].apply(lambda x: x.month)\n",
    "    df['year'] = df['date'].apply(lambda x: x.year)\n",
    "    \n",
    "    ## Fix Bool Columns\n",
    "\n",
    "    bool_col = ['available']\n",
    "    for bc in bool_col:\n",
    "        df[bc] = df[bc].replace({'t': True,'f':False})\n",
    "        df[bc] = df[bc].astype(bool)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing = pd.read_csv(PATH+'\\s_listings.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = pd.read_csv(PATH+'\\s_calendar.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing = clean_listings(df_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = clean_cal(df_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.What time of year is best to make your property availible to get the most money?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_cal.groupby(['month'])['price'].mean()).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.lineplot(x=df_cal['week_num'],y=df_cal['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.boxplot(y=df_cal['price'],x=df_cal['month'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.boxplot(y=df_cal['price'],x=df_cal['month'],showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ols('price ~ month',data=df_cal).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a boxplot\n",
    "df_cal.boxplot('price', by='month', figsize=(6, 4),showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END OF QUESTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:  Know your capacity?   Waht neighborhoods/property type/property attributes sell better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_clean_attr_data(df_list,df_cal):\n",
    "    \n",
    "    #Using the average list prices in df_cal['price'] vs the current listing price df_list['price']\n",
    "    df_avg_price = pd.DataFrame(df_cal.groupby(by=['listing_id'])['price'].mean())\n",
    "    df_list = df_list.drop(columns='price')\n",
    "    \n",
    "    \n",
    "    df = df_avg_price.merge(df_list,left_index=True,right_index=True)\n",
    "    \n",
    "    #Strip Xs down to the property/physical attributes of the property\n",
    "    ammenities = list(df.filter(like='amm').columns.values)\n",
    "    physical_attr_loc = ['price','bathrooms','bedrooms','beds','neighbourhood_cleansed',\n",
    "                     'neighbourhood_group_cleansed','property_type','room_type','bed_type',\n",
    "                    'accommodates','guests_included'] + ammenities\n",
    "    \n",
    "    df = df[physical_attr_loc]\n",
    "    ##Clean Nas \n",
    "    \n",
    "    # Drop all rows without a y (price)\n",
    "    df = df.dropna(axis=0,subset=['price'])\n",
    "    \n",
    "    # Dropping rows b/c The following had a low number of n/a rows and would be difficult to impute, \n",
    "    df = df.drop(index=df.loc[df['bedrooms'].isna(),:].index )\n",
    "    df = df.drop(index=df.loc[df['property_type'].isna(),:].index )\n",
    "    df = df.drop(index=df.loc[df['bathrooms'].isna(),:].index )\n",
    "    \n",
    "    \n",
    "    #Creating a log-transformed price column to \n",
    "    df.insert(column='price_log',loc=1,value=np.nan)\n",
    "    df['price_log'] = df['price'].apply(lambda x: np.log(x))\n",
    "    \n",
    "    # One hot encode the categorical columns\n",
    "    cat_col = list(df.select_dtypes(include='category').columns.values)\n",
    "    df = df.merge(pd.get_dummies(df[cat_col],prefix_sep='::'),right_index=True, left_index=True)\n",
    "    df = df.drop(columns=cat_col)\n",
    "    \n",
    "    #Standardize\n",
    "    std_col = ['price','price_log']\n",
    "    \n",
    "    #Normalize\n",
    "    norm_col = ['accommodates','guests_included','bathrooms','bedrooms','beds']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q2 = compile_and_clean_attr_data(df_listing,df_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize and Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize\n",
    "std_col = ['price','price_log']\n",
    "blah = StandardScaler()\n",
    "\n",
    "df_q2[std_col] = blah.fit_transform(df_q2[std_col])\n",
    "\n",
    "#Normalize\n",
    "norm_col = ['accommodates','guests_included','bathrooms','bedrooms','beds']\n",
    "\n",
    "df_q2[norm_col] = normalize(df_q2[norm_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q2_X = df_q2.drop(columns=['price','price_log'])\n",
    "df_q2_y1 = df_q2['price']\n",
    "df_q2_y2 = df_q2['price_log']\n",
    "\n",
    "q2_model = LinearRegression()\n",
    "\n",
    "q2_log_model = LinearRegression()\n",
    "\n",
    "q2_X_train, q2_X_test, q2_y1_train, q2_y1_test, q2_y2_train, q2_y2_test = train_test_split(df_q2_X,df_q2_y1,df_q2_y2,test_size = 0.3,random_state=72)\n",
    "\n",
    "q2_model.fit(q2_X_train,q2_y1_train)\n",
    "\n",
    "q2_log_model.fit(q2_X_train,q2_y2_train)\n",
    "\n",
    "q2_y1_predict = q2_model.predict(q2_X_test)\n",
    "\n",
    "q2_y2_predict = q2_log_model.predict(q2_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(q2_y1_test,q2_y1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(q2_y2_test,q2_y2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = pd.DataFrame()\n",
    "coefs_df['est_int'] = q2_X_train.columns\n",
    "coefs_df['coefs'] = q2_model.coef_\n",
    "coefs_df['abs_coefs'] = np.abs(q2_model.coef_)\n",
    "coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "coefs_df[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df['type'] = coefs_df['est_int'].apply(lambda x: x.split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df.groupby(by='type')['abs_coefs'].mean().sort_values(ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_room_type = df_cal.merge(df_listing[['room_type']],left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df_room_type['room_type'],y=df_room_type['price'],showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PCA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = pca.PCA(n_components=35)\n",
    "\n",
    "q2_X_pca = model_1.fit_transform(df_q2_X)\n",
    "\n",
    "model_1.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.scree_plot(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q2_X_pca = pd.DataFrame(q2_X_pca)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(df_q2_X_pca,df_q2_y1,test_size = 0.3,random_state=72)\n",
    "\n",
    "lmodel_pca = LinearRegression()\n",
    "\n",
    "lmodel_pca.fit(X_train_pca,y_train)\n",
    "\n",
    "y_predict_pca = lmodel_pca.predict(X_test_pca)\n",
    "\n",
    "r2_score(y_test,y_predict_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = h.pca_results_rng(df_q2_X,model_1,[1,25])\n",
    "pca_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = pca_results.drop(columns='Explained Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coefs_df = pd.DataFrame()\n",
    "pca_coefs_df['est_int'] = X_train_pca.columns\n",
    "pca_coefs_df['coefs'] = lmodel_pca.coef_\n",
    "pca_coefs_df['abs_coefs'] = np.abs(lmodel_pca.coef_)\n",
    "pca_coefs_df = pca_coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "pca_coefs_df[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_results.loc['Dimension 2',:].sort_values(ascending=False)[0:10])\n",
    "print(pca_results.loc['Dimension 2',:].sort_values(ascending=True)[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_results.loc['Dimension 24',:].sort_values(ascending=False)[0:10])\n",
    "print(pca_results.loc['Dimension 24',:].sort_values(ascending=True)[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_results.loc['Dimension 14',:].sort_values(ascending=False)[0:10])\n",
    "print(pca_results.loc['Dimension 14',:].sort_values(ascending=True)[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPARE NEIGHBOORHOODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_neighboorhoods=['Magnolia','Downtown','Queen Anne','West Seattle']\n",
    "\n",
    "def hotchecks(x,list):\n",
    "    if x in hot_neighboorhoods:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df_neigh = df_cal.merge(df_listing[['neighbourhood_group_cleansed']],left_index=True,right_index=True)\n",
    "\n",
    "df_neigh.insert(loc = df_neigh.shape[1],column='hot_neigh',value=False,)\n",
    "\n",
    "df_neigh['hot_neigh'] = df_neigh['neighbourhood_group_cleansed'].apply(lambda x: hotchecks(x,hot_neighboorhoods))\n",
    "\n",
    "month = {1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'Jun',7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'}\n",
    "\n",
    "df_neigh['month'] = df_neigh['month'].apply(lambda x: month[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,sharey=True)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.barplot(x=df_neigh['month'],y=df_neigh['price'],hue=df_neigh['hot_neigh'],ax=ax[1])\n",
    "sns.barplot(x=df_neigh['month'],y=df_neigh['price'],color='cyan',ax=ax[0])\n",
    "\n",
    "f.subplots_adjust(wspace=0.01, hspace=0)\n",
    "\n",
    "ax[1].set(ylim=(0, 220))\n",
    "ax[0].set(ylim=(0, 220))\n",
    "\n",
    "ax[0].set_ylabel('Price ($)')\n",
    "ax[1].set_ylabel('')\n",
    "ax[0].set_xlabel('')\n",
    "ax[1].set_xlabel('')\n",
    "\n",
    "ax[1].set_title('Average Price by Month across hot and not neighboorhoods')\n",
    "ax[0].set_title('Average Price by Month (All)')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neigh.groupby(by='neighbourhood_group_cleansed')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
